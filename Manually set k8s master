# k8s 集群 master 手工搭建


## 机器 && docker 版本
- Centos7.2 +/Oracle Linux 7.2+
- Docker-ce-17.03.2

版本信息：
- Kubernetes v1.9.1
- Etcd v3.1.10

官方指定的addons镜像版本信息
hub.yun.paic.com.cn/k8s/k8s-dns-kube-amd64:1.14.8
hub.yun.paic.com.cn/k8s/k8s-dns-dnsmasq-nanny-amd64:1.14.8
hub.yun.paic.com.cn/k8s/k8s-dns-sidecar-amd64:1.14.8
hub.yun.paic.com.cn/k8s/kubernetes-dashboard-amd64:1.8.0

 以下以POC环境搭建过程为例子
  K8S集群Master搭建
   机器&Docker版本
   1 二进制程序拷贝
   2 证书生成
      1.CA证书
      2.生成Etcd证书
      3.生成Kubernetes证书
   3 etcd部署
      1.准备etcd环境变量文件
      2.配置etcd.service并启动
      3.配置网络
   4 kube-apiserver部署
      1.准备环境变量文件
      2.准备service文件
      3.准备token.csv文件
      4.启动kube-apiserver
   5 kube-controller-manager部署
   6 kube-scheduler部署
   7 配置kubectl
   8 配置secret
   9 配置Role与RoleBinding
   10 配置DNS系统服务
   11 配置Dashboard
   
 1.二进制程序拷贝
 将下列二进制文件都拷贝到/usr/local/bin目录下：
  - etcd
  - etcdctl
  - kube-apiserver
  - kube-controller-manager
  - kube-scheduler
  - kubectl
  - cfssl
  - cfssl-certinfo
  - cfssljson
 同时授予执行权限
  > chmod +x /usr/local/bin
  
 2.证书生成
 (1) CA证书
 对于每一套k8s集群，会有唯一的一套CA证书，其余组件的证书都通过CA证书签发
 生成CA证书，其中配置文件ca-csr.json使用默认内容，如下：
 > # 文件名 ca-csr.json
 `
 {
    "CN": "kubernetes",
    "key": {
      "algo": "rsa",
      "size": 2048
    },
    "names": [
    {
      "C": "CN",
      "ST": "BeiJing",
      "L": "BeiJing",
      "O": "k8s",
      "OU": "System"
    }
    ]
 }
 `
 > 进入ca-csr.json所在目录下执行下方命令
  ` cfssl gencert -initca ca-csr.json | cfssljson -bare ca
 执行命令，生成两个文件: ca.pem;ca-key.pem
 将ca.pem,ca-key.pem拷贝到/etc/kubernetes/ssl目录下
 
 (2) 生成Etcd证书
  需要配置etcd签发证书的配置文件，etcd-crs.json内容如下，其中“$ETCD_IP_LIST”需要替换成部署etcd的服务器的真实IP。对于集群模式，需要写多行用逗号隔开
  > # 文件名： etcd-csr.json
  `
  {
    "CN": "etcd",
    "hosts": [
      "127.0.0.1",
      "$ETCD_IP_LIST"
    ],
    "key": {
      "algo": "rsa",
      "size": 2048
    },
    "names": [
      {
        "C": "CN",
        "ST": "BeiJing",
        "L": "BeiJing",
        "O": "k8s",
        "OU": "System"
      }
    ]
  }
  `
另外生成证书需要使用ca-config.json文件，内容如下：
> # 文件名：ca-config.json
`
{
  "signing":{
    "default": {
      "expiry": "8760h"
    },
    "profiles": {
      "kubernetes": {
        "usages": [
          "signing",
          "key encipherment",
          "server auth",
          "client auth"
        ],
        "expiry": "8760h"
      }
    }
  }
}
`
配置以后，执行下方命令生成etcd的证书和密钥
> cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes etcd-csr.json | cfssljson -bare etcd
执行后会生成：etcd.pem,etcd-key.pem，将其拷贝到/etc/etcd/ssl目录下
  (3)生成Kubernetes证书
  类似的，需要先配置kubernetes-csr.json文件，同时替换其中"$MASTER_IP"为kube-apiserver的VIP
  > # 文件名 kubernetes-csr.json
  `
  {
    "CN": "kubernetes",
    "hosts": [
      "127.0.0.1",
      "$MASTER_VIP",
      "172.254.0.1",
      "kubernetes",
      "kubernetes.default",
      "kubernetes.default.svc",
      "kubernetes.default.svc.cluster",
      "kubernetes.default.svc.cluster.local"
    ],
    "key": {
      "algo": "rsa",
      "size": 2048
    },
    "names": [
      {
        "C": "CN",
        "ST": "BeiJing",
        "L": "BeiJing",
        "O": k8s,
        "OU": "System"
      }
    ]
  }
  `
  > 配时候执行以下命令
  ` cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kubernetes-csr.json | cfssljson -bare kubernetes
  将生成的kubernetes.pem,kubernetes-key.pem拷贝到/etc/kubernetes/ssl目录下
  
  至此，Master部分需要的证书文件都已经生成完毕。
  
 3.etcd部署
  (1)准备etcd环境变量文件
  etcd-cluster.template文件，内容如下
  # 文件名 etcd-cluster.template
  ETCD_OPTIONS="--name=${HOST_NAME} \
    --client-cert-auth=true \
    --cert-file=/etc/etcd/ssl/etcd.pem \
    --key-file=/etc/etcd/ssl/etcd-key.pem \
    --peer-cert-file=/etc/etcd/ssl/etcd.pem \
    --peer-key-file=/etc/etcd/ssl/etcd-key.pem \
    --trusted-ca-file=/etc/kubernetes/ssl/ca.pem \
    --peer-trusted-ca-file=/etc/kubernetes/ssl/ca.pem \
    --initial-advertise-peerpurls=https://${HOST_IP}:2380 \
    --listen-peer-urls=https://${HOST_IP}:2380 \
    --listen-client-urls=https://${HOST_IP}:2379,https://127.0.0.1:2379 \
    --advertise-client-urls=https://${HOST_IP}:2379 \
    --initial-cluster-token=etcd-cluster-0 \
    --initial-cluster=${CLUSTER_ENDPOINTS} \
    --initial-cluster-state=new \
    --data-dir=/var/lib/etcd"
    
  需要替换的参数有：
  - ${HOST_NAME} 运行etcd服务的主机名
  - ${HOST_IP} 运行etcd服务的主机IP
  - ${CLUSTER_ENDPOINTS} 整个etcd集群中的主机信息以${主机名}=${主机IP}形式，类似下面
  ` --initial-cluster=CNSZ047071=https://10.25.65.31:2380,CNSZ047072=https://10.25.65.32:2380,CNSZ047073=https://10.25.65.33:2380
  替换后重命名为/etc/etcd/etcd文件
  
 (2)配置etcd.service并启动
 创建目录/var/lib/etcd
 创建/lib/systemd/system/etcd.service,该文件内容如下
 > # 文件名: etcd.service
 `
 [Uint]
 Description=Etcd Server
 After=network.target
 After=network-online.target
 Wants=network-online.target
 Documentation=https://github.com/coreos
 [Service]
 Type=notify
 WorkingDirectory=/var/lib/etcd/
 EnvironmentFile=/etc/etcd/etcd
 ExecStart=/usr/local/bin/etcd $ETCD_OPTIONS
 
 Restart=on-failure
 RestartSec=5
 LimitNOFILE=65536
 [Install]
 WantedBy=multi-user.target
 `
 并执行
 > systemctl deamon-reload
 需要对etcd集群中的所有节点都进行配置好，etcd服务之间可以使用相同的生死，配置好以后再依次启动etcd服务
 > systemctl start etcd.service
 
 (3)网络配置
 等etcd服务都启动，且正常以后，可以执行下列命令测试
 > etcdctl --endpoints=${ETCD_ENDPOINTS} --ca-file=/etc/kubernetes/ssl/ca.pem --cert-file=/etc/etcd/ssl/etcd.pem --key-file=/etc/etcd/ssl/etcd-key.pem ls /
 
 执行命令配置kubernetes网络，其中${ETCD_ENDPOINTS}需要替换，用逗号隔开
 > etcdctl --endpoints=${ETCD_ENDPOINTS} --ca-file=/etc/kubernetes/ssl/ca.pem --cert-file=/etc/etcd/ssl/etcd.pem --key-file=/etc/etcd/ssl/etcd-key.pem set /kubernetes/network/config "{\"Network\":\"172.1.0.0/16\", \"Subnetlen\":24, \"Backend\":{\"Type\":\"vxlan\"}}"
该命令会在etcd中生成/kubernetes/network/config文件，后续k8s相关组件会使用这个配置文件
** 至此etcd配置完成 **

4.kube-apiserver部署
 (1)准备环境变量文件
  kube-common.template，内容如下：
  > # kube-apiserver.template
  # etcd集群服务地址列表
  KUBE_ETCD_SERVERS="--etcd-servers=$ETCD_ENDPOINTS"
  KUBE_LOGTOSTDERR="--logtostderr=true"
  KUBE_LOG_LEVEL="--v=0"
  KUBE_ALLOW_PRIV="--allow-privileged=false"
  KUBE_MASTER="--master=http://$API_SERVER_ACCESS_IP:8080"
  KUBE_API_SERVER="https://$API_SERVER_ACCESS_IP:6443"
  # 服务望断（Service CIDR），部署前路由不可达，部署后集群内使用IP：Port可达
  KUBE_SERVICE_ADDRESSES="--service-cluster-ip-range-172.254.0.0/16"
  # kubernetes服务IP（预分配，一般是SERVICE_CIDR中第一个IP）
  CLUSTER_KUBERNETES_SVC_IP="172.254.0.1"
  # 集群DNS服务IP（从SERVICE_CIDR中预分配）
  CLUSTER_DNS_SVC_IP="--cluster-dns=172.254.0.2"
  # flanneld网络配置前缀
  FLANNELD_ETCD_PREFIX="--etcd-prefix=/kubernetes/network"
  > 替换其中的参数: $ETCD_ENDPOINTS,$API_SERVER_ACCESS，替换后重命名文件：/etc/kubernetes/kube-common
  
  apiserver.template内容如下：
  > # apiserver.template
  > # The address on the local server to listen to.
  KUBE_API_ADDRESS="--advertise-address=$API_SERVER_ACCESS_IP --bind-address=$API_SERVER_ACCESS_IP --insecure-bind-address=$API_SERVER_ACCESS_IP"
  
  > # The port on the local server to listen on.
  KUBE_API_PORT="--insecure-port=8080"
  
  KUBE_ADMISSION_CONTROL="--admission-controll=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ResourceQuota,ServiceAccount,NodeRestriction"
  
  # Add your own!
  KUBE_API_ARGS="--authorization-mode=RBAC,Node \
  --runtime-config=rbac.authorization.k8s.io/v1beta1 \
  --kubelet-https=true \
  --enable-bootstrap-token-auth \
  --token-auth-file=/etc/kubernetes/token.csv \
  --service-node-port-range=30000-32767 \
  --tls-ca-file=etc/kubernetes/ssl/ca.pem \
  --tls-cert-file=/etc/kubernetes/ssl/kubernetes.pem \
  --tls-private-key-file=/etc/kubernetes/ssl/kubernetes-key.pem \
  --client-ca-file=/etc/kubernetes/ssl/ca.pem \
  --service-account-key-file=/etc/kubernetes/ssl/ca-key.pem \
  --etcd-cafile=/etc/kubernetes/ssl/ca.pem \
  --etcd-certfile=/etc/etcd/ssl/etcd.pem \
  --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem \
  --enable-swagger-ui=true \
  --audit-log-maxage=30 \
  --audit-log-maxbackup=3 \
  --audit-log-maxsize=100 \
  --audit-log-path=/var/lib/audit.log \
  --event-ttl=5h \
  --v=2"
  > 替换变量 $API_SERVER_ACCESS_IP，替换之后重命名为：/etc/kubernetes/apiserver文件
  ** 在k8s 1.8以后，node节点有一个专门的认证模式和RBAC同级叫做Node，同时应该在--admission-control中开启NodeRestriction
  
  (2)准备service文件
  创建/lib/systemd/system/kube-apiserver.service,并启动服务，kube-apiserver.service的内容如下：
  # kube-apiserver.service
  [Unit]
  Description=Kubernetes API Server
  Documentation=https://github.com/GoogleCloudPlatform/kubernetes
  After=network.target
  
  [Service]
  EnvironmrntFile=-/etc/kubernetes/kube-common
  EnvironmentFile=-/etc/kubernetes/apiserver
  ExecStart=/usr/local/bin/kube-api-server \
           $KUBE_LOGTOSTDERR \
           $KUBE_LOG_LEVEL \
           $KUBE_ETCD_SERVERS \
           $KUBE_API_ADDRESS \
           $KUBE_API_PORT \
           $KUBE_ALLOW_PRIV \
           $KUBE_SERVICE_ADDRESSES \
           $KUBE_ADMISSION_CONTROL \
           $KUBE_API_ARGS
  Restart=on-failure
  Type=notify
  LimitNOFILE=65536
  
  [Install]
  WantedBy=multi-user.target
  
  (3)准备token.csv文件
  kubelet首次启动时向kube-apiserver发送TLS Bootstrapping请求，kubeapiserver严重kubelet请求中的token是否与它配置的token.csv一直，如果一直则自动为kubelet生成证书和密钥
  aaa,${VPC_NAME},10235,"system:kubelet-bootstrap"
  其中，第一段是一个uuid，可以通过命令生成
  > head -c 16 /dev/urandom | od -An -t x | tr -d ' '
  第二段是VPC名称，当配置好kubectl后，我们需要创建一个以VPC名称命名的权限绑定，后续添加 node的时候需要使用，第三个数字作为标记，可以任意写，可以重复。最后一个固定系统角色，不建议修改
  
  (4)启动kube-api-server
  ` systemctl daemon-reload && systemctl start kube-apiserver.service
  
5.kube-controller-manager部署
kube-controller-manager文件不需要替换内容，创建/etc/kubernetes/controller-manager文件如下：
> # kube-controller-manager
KUBE_CONTROLLER_MANAGER_ARGS="--service-cluster-ip-range=172.254.0.0/16 \
--cluster-name=kubernetes \
--cluster-cidr=172.1.0.0/16 \
--address=127.0.0.1 \
--allocate-node-cidrs=true \
--cluster-signing-cert-file=/etc/kubernetes/ssl/ca.pem \
--cluster-signing-key-file=/etc/kubernetes/ssl/ca-key.pem \
--service-account-private-key-file=/etc/kubernetes/ssl/ca-key.pem \
--root-ca-file=/etc/kubernetes/ssl/ca.pem \
--leader-elect=true"

生成/lib/systemd/system/kube-controller-manager.service
> 启动服务 systemctl daemon-reload && systemctl start kube-controllr-manager.service

6.kube-scheduler部署
kube-scheduler文件不需要替换内容，创建/etc/kubernetes/scheduler文件如下：
> KUBE_SCHEDULER_ARGS="--address=127.0.0.1 --leader-elect=true"
生成文件:/lib/systemd/system/kube-scheduler.service
> 启动服务：systemctl daemon-reload && systemctl start kube-scheduler.service

7.配置kubectl
对于Master主机上的kubectl可以直接使用8080非tls端口，配置如下：
kubectl config set-cluster kubernetes --server=http://$HOST:$PORT
kubectl config set-credentials kubectl
kubectl config set-context kubernetes --cluster=kubernetes --user=kubectl --namespace=${namespace}
kubectl config use-context kubernetes

8.配置secret
镜像仓库开启了鉴权，我们需要创建secret，其中指定访问registry的账户信息，这里我们给定了一个超级用户，能够下载任何镜像
> kubectl create secret docker-registry ${secretName} --docker-server=ysf.site.com --docker-password='123456' --docker-email="xx@163.com" --namespace=${namespace}
如果仅仅创建了secret，在部署的时候，需要显式地在yaml文件中指定secret名称，这样非常不方便，我们可以将secret配置到默认的名称为default的ServiceAccount之中，这样在部署的时候k8s会默认使用它。命令如下
> kubectl patch sa default --namespace="${namespace}" -p '{"imagePullSecrets":[{"name":"default"}]}'
** 以上一组命令需要对每一个namespace执行

9.配置Role与RoleBinding

10.配置DNS系统服务
配置DNS服务可以用下面的yaml文件，其中包括几个部分
- ServiceAccount
- ConfigMap
- Deployment
- Service

11.配置Dashboard
